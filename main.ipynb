{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a Pattern Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_A =  np.array(\n",
    "    [\n",
    "        [ 0,  0,  0,  1,  1,  0,  0,  0],\n",
    "        [ 0,  0,  1,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_B = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_C = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_D = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_E = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_F = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_G = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  1,  1,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_H = np.array(\n",
    "    [\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_I = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  1],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  1,  0,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_J = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  1,  1],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  1,  1,  1,  0,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_K = np.array(\n",
    "    [\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_L = np.array(\n",
    "    [\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_M = np.array(\n",
    "    [\n",
    "        [ 1,  1,  0,  0,  0,  1,  1,  0],\n",
    "        [ 1,  0,  1,  0,  1,  0,  1,  0],\n",
    "        [ 1,  0,  0,  1,  0,  0,  1,  0],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  0],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  0],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  0],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  0],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_N = np.array(\n",
    "    [\n",
    "        [ 1,  0,  0,  0,  0,  0,  0,  1],\n",
    "        [ 1,  1,  0,  0,  0,  0,  0,  1],\n",
    "        [ 1,  0,  1,  0,  0,  0,  0,  1],\n",
    "        [ 1,  0,  0,  1,  0,  0,  0,  1],\n",
    "        [ 1,  0,  0,  0,  1,  0,  0,  1],\n",
    "        [ 1,  0,  0,  0,  0,  1,  0,  1],\n",
    "        [ 1,  0,  0,  0,  0,  0,  1,  1],\n",
    "        [ 1,  0,  0,  0,  0,  0,  0,  1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_O = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_P = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_Q = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  1,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  1,  1,  1,  0,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_R = np.array(\n",
    "    [\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_S = np.array(\n",
    "    [\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  0,  1,  1,  1,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  1,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  1,  0,  0,  0,  0,  1,  0],\n",
    "        [ 0,  0,  1,  1,  1,  1,  0,  0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "pattern_T = np.array(\n",
    "    [\n",
    "        [ 1,  1,  1,  1,  1,  1,  1,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pattern(pattern, label):\n",
    "    plt.figure(figsize=(2, 2*6/5))\n",
    "    y0, x0 = np.where(pattern == 0)\n",
    "    y1, x1 = np.where(pattern == 1)\n",
    "    plt.scatter(x0, y0, marker='o', s=5, color='black')\n",
    "    plt.scatter(x1, y1, marker='s', s=100, color='black')\n",
    "    #plt.text(0.5, -0.1, f'Pattern {label}', va='top', ha='center')\n",
    "    plt.axis('off')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pattern_fade(pattern):\n",
    "    plt.figure(figsize=(2, 2*6/5))\n",
    "    reversed_pattern = np.flipud(pattern.reshape((8, 8)))\n",
    "    plt.imshow(reversed_pattern, cmap='binary')\n",
    "    plt.axis('off')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_list = [pattern_A, pattern_B, pattern_C, pattern_D, pattern_E, pattern_F, pattern_G, pattern_H, pattern_I, pattern_J,\n",
    "                pattern_K, pattern_L, pattern_M, pattern_N, pattern_O, pattern_P, pattern_Q, pattern_R, pattern_S, pattern_T]\n",
    "pattern_array = np.array(pattern_list)\n",
    "label_list = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_array_flatten = np.vstack([p.flatten() for p in pattern_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_pattern(pattern, noise_ratio):\n",
    "    num_elements_to_flip = int(noise_ratio * pattern.size)\n",
    "    indices_to_flip = np.random.choice(pattern.size, num_elements_to_flip, replace=False)\n",
    "    noisy_pattern = np.copy(pattern)\n",
    "    noisy_pattern.flat[indices_to_flip] = np.logical_not(noisy_pattern.flat[indices_to_flip])\n",
    "    \n",
    "    return noisy_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_patterns(pattern_list, noise_ratio):\n",
    "    return np.array([add_noise_to_pattern(pattern, noise_ratio) for pattern in pattern_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_patterns = add_noise_to_patterns(pattern_list, 0.25)\n",
    "noisy_patterns_flatten = np.vstack([p.flatten() for p in noisy_patterns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patterns(pattern_list, label_list):\n",
    "    fig, axs = plt.subplots(len(pattern_list)//5+(len(pattern_list) % 5 != 0), 5, figsize=(6, 6*5/4))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Custom colormap: 0 values are black, 1 values are gray\n",
    "    #colors = [(0, 0, 0), (0.1, 0.1, 0.1)]\n",
    "    colors = [\"gray\", \"black\"]\n",
    "    n_bins = [-1, 1]\n",
    "    cmap_name = 'black_and_gray'\n",
    "    black_gray_cmap = LinearSegmentedColormap.from_list(cmap_name, list(zip(n_bins, colors)))\n",
    "\n",
    "    for i, pattern in enumerate(pattern_list):\n",
    "        #axs[i].imshow(pattern, cmap=black_gray_cmap, interpolation='nearest')\n",
    "        y0, x0 = np.where(pattern == 0)\n",
    "        y1, x1 = np.where(pattern == 1)\n",
    "        axs[i].scatter(x0, y0, marker='o', s=5, color='black')\n",
    "        axs[i].scatter(x1, y1, marker='s', s=60, color='black')\n",
    "        if label_list != None:\n",
    "            axs[i].text(0.5, -0.1, f'Pattern \"{label_list[i]}\"', va='top', ha='center', transform=axs[i].transAxes)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].invert_yaxis()\n",
    "        for j in range(i + 1, len(axs)):\n",
    "            axs[j].axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patterns_fade(pattern_list):\n",
    "    fig, axs = plt.subplots(len(pattern_list)//5+(len(pattern_list) % 5 != 0), 5, figsize=(6, 6*5/4))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, pattern in enumerate(pattern_list):\n",
    "        reversed_pattern = np.flipud(pattern.reshape((8, 8)))\n",
    "        axs[i].imshow(reversed_pattern, cmap='binary')\n",
    "        axs[i].axis('off')\n",
    "        axs[i].axis('off')\n",
    "        axs[i].invert_yaxis()\n",
    "        for j in range(i + 1, len(axs)):\n",
    "            axs[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patterns_fade2(pattern_list, label_list=None):\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(10, 8))  # Adjust the subplot grid as necessary\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.clear()  # Clear the plot (important if you're updating the plots in a loop)\n",
    "        ax.axis('off')  # Hide the axis\n",
    "\n",
    "    for i, (category, pattern) in enumerate(pattern_list):\n",
    "        axs[i].imshow(pattern.reshape((8, 8)), cmap='binary')\n",
    "        if label_list is not None:\n",
    "            axs[i].set_title(f'Category {label_list[category]}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patterns(pattern_array, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patterns(noisy_patterns, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ART1:\n",
    "    def __init__(self, n_features, n_categories, vigilance=0.5, learning_rate=1.0, penalty_rate=0.0):\n",
    "        self.n_features = n_features\n",
    "        self.n_categories = n_categories\n",
    "        self.vigilance = vigilance\n",
    "        self.learning_rate = learning_rate\n",
    "        self.penalty_rate = penalty_rate\n",
    "\n",
    "        # Initialize weights\n",
    "        self.bottom_up_weights = np.ones((n_categories, n_features)) * (1.0 / (1 + n_features))\n",
    "        self.top_down_weights = np.ones((n_categories, n_features))\n",
    "\n",
    "    def calculate_match_score(self, input_pattern, category):\n",
    "        match_score = np.sum(np.minimum(input_pattern, self.top_down_weights[category]))\n",
    "        return match_score\n",
    "\n",
    "    def calculate_similarity(self, input_pattern, category):\n",
    "        intersection = np.sum(np.minimum(input_pattern, self.top_down_weights[category]))\n",
    "        norm_input = np.sum(input_pattern)\n",
    "        penalty = np.sum(np.logical_and(input_pattern == 0, self.top_down_weights[category] == 1)) * self.penalty_rate\n",
    "        penaltied_intersection = max(0, intersection - penalty)\n",
    "        return penaltied_intersection / norm_input if norm_input > 0 else 0\n",
    "\n",
    "    \"\"\"\n",
    "    def classify(self, input_pattern):\n",
    "        match_scores = [self.calculate_match_score(input_pattern, i) for i in range(self.n_categories)]\n",
    "        best_category = np.argmax(match_scores)\n",
    "        \n",
    "        if self.calculate_similarity(input_pattern, best_category) >= self.vigilance:\n",
    "            return best_category\n",
    "\n",
    "        match_scores[best_category] = -1  # Mark the current best category as invalid\n",
    "        next_best_category = np.argmax(match_scores)\n",
    "\n",
    "        while next_best_category != best_category: \n",
    "            if self.calculate_similarity(input_pattern, next_best_category) >= self.vigilance:\n",
    "                return next_best_category\n",
    "            match_scores[next_best_category] = -1\n",
    "            best_category = next_best_category\n",
    "            next_best_category = np.argmax(match_scores)\n",
    "\n",
    "        return None\n",
    "    \"\"\"\n",
    "\n",
    "    def classify(self, input_pattern):\n",
    "        similarities = [self.calculate_similarity(input_pattern, i) for i in range(self.n_categories)]\n",
    "        best_category = np.argmax(similarities)\n",
    "        for _ in range(self.n_categories):\n",
    "            if similarities[best_category] >= self.vigilance:\n",
    "                return best_category\n",
    "            similarities[best_category] = -1\n",
    "        return None\n",
    "\n",
    "\n",
    "    def update_weights(self, input_pattern, category):\n",
    "        self.top_down_weights[category] = self.learning_rate * np.minimum(input_pattern, self.top_down_weights[category]) + \\\n",
    "                                          (1 - self.learning_rate) * self.top_down_weights[category]\n",
    "        norm_factor = np.sum(self.top_down_weights[category]) if np.sum(self.top_down_weights[category]) > 0 else 1\n",
    "        self.bottom_up_weights[category] = self.top_down_weights[category] / norm_factor\n",
    "\n",
    "    def train(self, input_patterns, epochs=1, verbose=False, plot_verbose=False):\n",
    "        for epoch in range(epochs):\n",
    "            for step, input_pattern in enumerate(input_patterns):\n",
    "                category = self.classify(input_pattern)\n",
    "                if category is not None:\n",
    "                    self.update_weights(input_pattern, category)\n",
    "                    if verbose:\n",
    "                        print(f\"Epoch {epoch}, Input pattern classified into category {category}.\")\n",
    "                    if plot_verbose:\n",
    "                        self.plot_current_state(step, category)\n",
    "\n",
    "    def plot_current_state(self, step, category):\n",
    "        fig, axs = plt.subplots(1, self.n_categories, figsize=(20, 2))\n",
    "        for idx, ax in enumerate(axs):\n",
    "            ax.imshow(self.top_down_weights[idx].reshape((8, 8)), cmap='binary')\n",
    "            ax.set_title(f'Cat. {idx}')\n",
    "            ax.axis('off')\n",
    "        plt.suptitle(f'Step {step + 1} - Updated Category {category}')\n",
    "        plt.show()\n",
    "\n",
    "    def sort_categories(self, original_patterns):\n",
    "        sorted_weights = np.zeros_like(self.top_down_weights)\n",
    "        for i, pattern in enumerate(original_patterns):\n",
    "            category = self.classify(pattern)\n",
    "            if category is not None:\n",
    "                sorted_weights[i] = self.top_down_weights[category]\n",
    "            else:\n",
    "                print(f\"Pattern at index {i} cannot be classified.\")\n",
    "        self.top_down_weights = sorted_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART1N = ART1(n_features=64, n_categories=20, vigilance=0.8, learning_rate=0.1) #not bad\n",
    "# ART1N = ART1(n_features=64, n_categories=20, vigilance=0.7, learning_rate=0.5) #not bad\n",
    "# ART1N = ART1(n_features=64, n_categories=20, vigilance=0.75, learning_rate=0.3, penalty_rate=0.001) #good\n",
    "# ART1N = ART1(n_features=64, n_categories=20, vigilance=0.5, learning_rate=0.5, penalty_rate=0.001)\n",
    "ART1N = ART1(n_features=64, n_categories=20, vigilance=0.5, learning_rate=1, penalty_rate=0.001)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    shuffled_patterns = np.copy(pattern_array_flatten)\n",
    "    np.random.shuffle(shuffled_patterns)\n",
    "    ART1N.train(shuffled_patterns, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ART1N.sort_categories(pattern_array_flatten)\n",
    "stored_patterns = ART1N.top_down_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patterns_fade(stored_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_recalled_flat = pattern_C.flatten()\n",
    "category = ART1N.classify(pattern_recalled_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_array = np.zeros(np.shape(pattern_array)[0])\n",
    "for i, pattern in enumerate(pattern_array):\n",
    "    pattern_flat = pattern.flatten()\n",
    "    category_array[i] = ART1N.classify(pattern_flat)\n",
    "print(category_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_array = np.zeros(np.shape(pattern_array)[0])\n",
    "for i, pattern in enumerate(noisy_patterns):\n",
    "    pattern_flat = pattern.flatten()\n",
    "    category_array[i] = ART1N.classify(pattern_flat)\n",
    "print(category_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analysis with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(ART1_network, original_patterns, patterns_to_classify):\n",
    "    num_patterns = len(original_patterns)+1\n",
    "    confusion_matrix = np.zeros((num_patterns, num_patterns), dtype=int)\n",
    "    permutation_indices = np.random.permutation(len(patterns_to_classify))\n",
    "    shuffled_patterns = np.copy(patterns_to_classify)\n",
    "    shuffled_patterns = shuffled_patterns[permutation_indices]\n",
    "\n",
    "    for i, pattern in enumerate(shuffled_patterns):\n",
    "        pattern_flat = pattern.flatten()\n",
    "        j = ART1_network.classify(pattern_flat)\n",
    "        #print(i, j)\n",
    "        if j == None:\n",
    "            j = num_patterns-1\n",
    "        confusion_matrix[permutation_indices[i], j] += 1\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix_metrics(confusion_matrix, class_index):\n",
    "    TP = confusion_matrix[class_index, class_index]\n",
    "    FP = confusion_matrix[:, class_index].sum() - TP\n",
    "    FN = confusion_matrix[class_index, :].sum() - TP\n",
    "    TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def calculate_accuracy(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "def calculate_recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def calculate_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def calculate_F1(TP, FP, FN):\n",
    "    return 2*TP / (2*TP + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_confusion_matrix(ART1_network, original_patterns, n, noise_ratio):\n",
    "    num_patterns = len(original_patterns)+1\n",
    "    n_confusion_matrix = np.zeros((num_patterns, num_patterns), dtype=int)\n",
    "    for _ in range(n):\n",
    "        noisy_patterns = add_noise_to_patterns(original_patterns, noise_ratio)\n",
    "        confusion_matrix = np.copy(generate_confusion_matrix(ART1_network, original_patterns, noisy_patterns))\n",
    "        n_confusion_matrix = np.copy(n_confusion_matrix) + np.copy(confusion_matrix)\n",
    "    return n_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_accuracy(confusion_matrix):\n",
    "    correct_predictions = np.trace(confusion_matrix)\n",
    "    total_predictions = np.sum(confusion_matrix)\n",
    "    overall_accuracy = correct_predictions / total_predictions\n",
    "    return overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    plt.figure(figsize=(9, 6)) \n",
    "    sns.set()\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g',\n",
    "                     xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 10})\n",
    "    \n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = generate_confusion_matrix(ART1N, pattern_array, pattern_array)\n",
    "plot_confusion_matrix(confusion_matrix, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_confusion_matrix = generate_n_confusion_matrix(ART1N, original_patterns=pattern_array, n=1000, noise_ratio=0.)\n",
    "plot_confusion_matrix(n_confusion_matrix, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = calculate_confusion_matrix_metrics(n_confusion_matrix, 11)\n",
    "print(TP, TN, FP, FN)\n",
    "acc = calculate_accuracy(TP, TN, FP, FN)\n",
    "precision = calculate_precision(TP, FP)\n",
    "recall = calculate_recall(TP, FN)\n",
    "F1 = calculate_F1(TP, FP, FN)\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {F1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_overall_accuracy(n_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vigilance_analysis(learning_rate, penalty_rate, noise_ratio, num_epochs=5, n_features=64, n_categories=20, n=1000, verbose=False):\n",
    "    overall_accuracies = []\n",
    "    vigilance_array = np.arange(0.0, 1.01, 0.05)\n",
    "    for vigilance in vigilance_array:\n",
    "        print(vigilance)\n",
    "        ART1network = ART1(n_features, n_categories, vigilance, learning_rate, penalty_rate)\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffled_patterns = np.copy(pattern_array_flatten)\n",
    "            np.random.shuffle(shuffled_patterns)\n",
    "            ART1network.train(shuffled_patterns)\n",
    "        ART1network.sort_categories(pattern_array_flatten)\n",
    "        n_confusion_matrix = generate_n_confusion_matrix(ART1network, original_patterns=pattern_array, n=n, noise_ratio=noise_ratio)\n",
    "        copy_n_confusion_matrix = np.copy(n_confusion_matrix)\n",
    "        overall_accuracies.append(calculate_overall_accuracy(copy_n_confusion_matrix))\n",
    "    return vigilance_array, overall_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vigilance_analysis(vigilance_array, overall_accuracies):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(vigilance_array, overall_accuracies)\n",
    "    plt.title('Average overall accuracy vs vigilance')\n",
    "    plt.xlabel('Vigilance')\n",
    "    plt.ylabel('Overall accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vigilance_range, overall_accuracies = vigilance_analysis(n_features=64, n_categories=20, num_epochs=10, learning_rate=1, penalty_rate=0.001, noise_ratio=0.1, n=500, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vigilance_analysis(vigilance_range, overall_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_analysis(learning_rate, penalty_rate, vigilance, num_epochs=5, n_features=64, n_categories=20, n=1000, verbose=False):\n",
    "    overall_accuracies = []\n",
    "    noise_ratio_array = np.arange(0, 0.251, 0.025)\n",
    "    for noise_ratio in noise_ratio_array:\n",
    "        print(noise_ratio)\n",
    "        ART1network = ART1(n_features, n_categories, vigilance, learning_rate, penalty_rate)\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffled_patterns = np.copy(pattern_array_flatten)\n",
    "            np.random.shuffle(shuffled_patterns)\n",
    "            ART1network.train(shuffled_patterns)\n",
    "        ART1network.sort_categories(pattern_array_flatten)\n",
    "        n_confusion_matrix = generate_n_confusion_matrix(ART1network, original_patterns=pattern_array, n=n, noise_ratio=noise_ratio)\n",
    "        overall_accuracies.append(calculate_overall_accuracy(n_confusion_matrix))\n",
    "    return noise_ratio_array, overall_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_analysis(noise_ratio_array, overall_accuracies):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(noise_ratio_array, overall_accuracies)\n",
    "    plt.title('Average overall accuracy vs noise ratio')\n",
    "    plt.xlabel('Noise ratio')\n",
    "    plt.ylabel('Overall accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_ratio_range, overall_accuracies = noise_analysis(n_features=64, n_categories=20, num_epochs=10, learning_rate=1, vigilance=0.2, penalty_rate=0.001, n=500, verbose=False)\n",
    "plot_noise_analysis(noise_ratio_range, overall_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_analysis(penalty_rate, vigilance, num_epochs=5, n_features=64, n_categories=20, n=1000, noise_ratio=0.25):\n",
    "    overall_accuracies = []\n",
    "    learning_rate_array = np.arange(0, 1.01, 0.05)\n",
    "    for learning_rate in learning_rate_array:\n",
    "        print(learning_rate)\n",
    "        ART1network = ART1(n_features, n_categories, vigilance, learning_rate, penalty_rate)\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffled_patterns = np.copy(pattern_array_flatten)\n",
    "            np.random.shuffle(shuffled_patterns)\n",
    "            ART1network.train(shuffled_patterns)\n",
    "        ART1network.sort_categories(pattern_array_flatten)\n",
    "        n_confusion_matrix = generate_n_confusion_matrix(ART1network, original_patterns=pattern_array, n=n, noise_ratio=noise_ratio)\n",
    "        #plot_confusion_matrix(n_confusion_matrix, label_list)\n",
    "        overall_accuracies.append(calculate_overall_accuracy(n_confusion_matrix))\n",
    "    return learning_rate_array, overall_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_rate_analysis(learning_rate_array, overall_accuracies):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(learning_rate_array, overall_accuracies)\n",
    "    plt.title('Average overall accuracy vs learning rate')\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.ylabel('Overall accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_array, overall_accuracies = learning_rate_analysis(n_features=64, n_categories=20, num_epochs=10, vigilance=0.5, penalty_rate=0.001, n=300, noise_ratio=0.0)\n",
    "plot_learning_rate_analysis(learning_rate_array, overall_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_rate_analysis(learning_rate, vigilance, num_epochs=5, n_features=64, n_categories=20, n=1000, noise_ratio=0.25):\n",
    "    overall_accuracies = []\n",
    "    penalty_rate_array = np.array([1e-19, 1e-18, 1e-17, 5e-17, 1e-16, 5e-16, 1e-15, 1e-12, 1e-9, 1e-6, 0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25])\n",
    "    for penalty_rate in penalty_rate_array:\n",
    "        print(penalty_rate)\n",
    "        ART1network = ART1(n_features, n_categories, vigilance, learning_rate, penalty_rate)\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffled_patterns = np.copy(pattern_array_flatten)\n",
    "            np.random.shuffle(shuffled_patterns)\n",
    "            ART1network.train(shuffled_patterns)\n",
    "        ART1network.sort_categories(pattern_array_flatten)\n",
    "        n_confusion_matrix = generate_n_confusion_matrix(ART1network, original_patterns=pattern_array, n=n, noise_ratio=noise_ratio)\n",
    "        #plot_confusion_matrix(n_confusion_matrix, label_list)\n",
    "        overall_accuracies.append(calculate_overall_accuracy(n_confusion_matrix))\n",
    "    return penalty_rate_array, overall_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_penalty_rate_analysis(penalty_rate_array, overall_accuracies):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(penalty_rate_array, overall_accuracies, 'o-')\n",
    "    plt.title('Average overall accuracy vs penalty rate')\n",
    "    plt.xlabel('Penalty rate')\n",
    "    #plt.xlim(left=penalty_rate_array[0], right=penalty_rate_array[-1])\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('Overall accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_rate_array, overall_accuracies = penalty_rate_analysis(n_features=64, n_categories=20, num_epochs=10, vigilance=0.5, learning_rate=1.0, n=100, noise_ratio=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_penalty_rate_analysis(penalty_rate_array, overall_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
